report_text = """# Reporte ‚Äì Clasificaci√≥n de Ingresos

## 1. Decisiones de procesamiento de datos

- **Uso de caracter√≠sticas**:  
  Se utilizaron todas las variables originales del dataset *Adult* (edad, nivel educativo, ocupaci√≥n, sexo, horas por semana, etc.). No se crearon variables nuevas derivadas de combinaciones.

- **Tratamiento de valores faltantes**:  
  - Variables num√©ricas ‚Üí imputadas con la **mediana**.  
  - Variables categ√≥ricas ‚Üí imputadas con el valor `"Unknown"`.  

- **Transformaciones aplicadas**:  
  - **Num√©ricas**: estandarizaci√≥n con `StandardScaler` (media 0, varianza 1).  
  - **Categ√≥ricas**: codificaci√≥n con **One-Hot Encoding** (`OneHotEncoder`).  

- **Balanceo de clases**:  
  Se aplic√≥ **SMOTE (Synthetic Minority Oversampling Technique)** para crear ejemplos sint√©ticos de la clase minoritaria (>50K), corrigiendo el desbalance.

- **Separaci√≥n de conjuntos**:  
  - `train`: entrenamiento del modelo.  
  - `validaci√≥n`: comparaci√≥n de configuraciones (hiperpar√°metros).  
  - `Prueba final`: evaluaci√≥n del mejor modelo, sin usarse en fases anteriores.

---

## 2. Hiperpar√°metros del mejor MLP

El mejor modelo fue **Experimento4**, con la siguiente configuraci√≥n base:

- Arquitectura: `[1024, 512]` (dos capas ocultas de 1024 y 512 neuronas).  
- Funci√≥n de activaci√≥n: ReLU.  
- Dropout: `0.3`.  
- Learning rate: `1e-4`.  
- Weight decay (regularizaci√≥n L2): `1e-3`.  
- Batch size: `1024`.  
- √âpocas m√°ximas: `60`.  

### Variantes probadas en la arquitectura
Durante los experimentos se probaron tambi√©n:
- `[1024, 512, 256]`  
- `[1024, 512, 128]`  
- `[1024, 512, 2]`  

En todos los casos, el modelo con arquitectura `[1024, 512]` se mantuvo como el m√°s robusto y con mejor desempe√±o en validaci√≥n y test, superando a los **experimentos 1, 2, 3 y 5**.

### Comparaci√≥n con y sin regularizaci√≥n
- **Sin regularizaci√≥n** (Experimento1, dropout=0, weight_decay=0):  
  - Training loss baj√≥ r√°pidamente, pero validation loss se dispar√≥ ‚Üí Esto es un s√≠ntoma de *overfitting*.  
  - AUC menor en validaci√≥n.  

- **Con regularizaci√≥n (Experimento4)**:  
  - Training y validation loss se mantuvieron cercanos y estables.  
  - Mejor **ROC AUC = 0.915** en test.  

üëâ **Conclusi√≥n**: La mejor combinaci√≥n fue una red de alta capacidad con regularizaci√≥n adecuada, que evit√≥ el sobreajuste y mejor√≥ la generalizaci√≥n.

---

## 3. Comparaci√≥n del mejor MLP vs regresi√≥n log√≠stica

- **Regresi√≥n log√≠stica (baseline)**:  
  - ROC AUC en test: **0.9075**  
  - Ventajas: simple, interpretable, muy competitivo.

- **Mejor MLP (exp4)**:  
  - ROC AUC en test: **0.9147**  
  - Accuracy: **0.827**  
  - Precision: **0.597**  
  - Recall: **0.829**  
  - F1: **0.694**  

### Interpretaci√≥n
- Ambos modelos presentan un rendimiento s√≥lido y acertado.  
- El MLP mejora ligeramente el AUC respecto a la regresi√≥n log√≠stica (0.7 puntos por encima de la regresi√≥n log√≠stica).  
- El MLP captura mejor relaciones no lineales entre variables.  
- Sin embargo, la regresi√≥n log√≠stica sigue siendo una opci√≥n fuerte si se prioriza la simplicidad e interpretabilidad.

üëâ **Conclusi√≥n** 
El MLP es superior en desempe√±o, pero la ganancia debe evaluarse frente al mayor costo computacional ya que este necesit√≥ de m√°s ram y se necesit√≥ correrlo mediante GPU y puede ser m√°s dif√≠cil de interpretar.

**Nota**: Para la realizaci√≥n de este trabajo se utiliz√≥ la asistencia de herramientas de inteligencia artificial como ChatGPT y Gemini con el objetivo de corregir errores de sintaxis en el c√≥digo y aclarar conceptos netamente te√≥ricos. Todas las decisiones de modelado, procesamiento de datos y selecci√≥n de hiperpar√°metros fueron tomadas de manera aut√≥noma en el desarrollo del proyecto.
"""
